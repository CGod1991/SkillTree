# 表数据迁移

标签：HBase 数据迁移

---

## Import 和 Export

这种方式适合数据量不是很大的表。如果数据量比较大的话，短时间内会有大量数据写入 HBase 集群，会造成某个 Region 的写入压力过大，报 RegionTooBusy 异常。

由于这次只是从老集群中迁移几个表到新集群中，所以只能采用在线迁移的方式。HBase 本身提供了在线迁移的工具：org.apache.hadoop.hbase.mapreduce.Export 和 org.apache.hadoop.hbase.mapreduce.Import。

具体步骤如下：
1. 在老集群中执行命令：
> $HBASE_HOME/bin/hbase org.apache.hadoop.hbase.mapreduce.Export test hdfs://new cluster ip:9000/test_out

2. 在新集群中创建对应的表，注意表结构和老集群中要保持一致。
3. 在新集群中执行命令：
> $HBASE_HOME/bin/hbase  org.apache.hadoop.hbase.mapreduce.Import test hdfs://new cluster ip:9000/test_out

## distcp

对于数据量比较大的表，可以使用 Hadoop 的 distcp 命令，先将表对应的 HDFS 上的目录拷贝到新集群，然后使用 HBase hbck -fixMeta -fixAssignments 命令更新 HBase 元数据即可。

需要注意的是，新集群上的目录要和老集群保持一致。

如果迁移到新集群后，需要修改表名或者移动到其他的 namespace ，则需要在迁移成功后，使用 HBase 的 snapshot 特性修改表名，具体步骤如下：
```shell
hbase shell> disable 'tableName'
hbase shell> snapshot 'tableName', 'tableSnapshot'
hbase shell> clone_snapshot 'tableSnapshot', 'newTableName'
hbase shell> delete_snapshot 'tableSnapshot'
hbase shell> drop 'tableName'
```