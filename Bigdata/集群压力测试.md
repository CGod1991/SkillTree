# 集群压力测试

标签：压测

---

简单介绍一些大数据集群做压力测试所使用的工具，以及测试的具体过程。

## HDFS

Hadoop 自带了一个 jar 包用来做各种的压力测试和性能测试，jar 包所在路径为 `$HADOOP_HOME/share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar`。

在对集群进行压力测试之前，可以先对集群当前的性能做一个测试，先了解集群的大体性能。

可以使用 TestDFSIO 对集群进行性能测试。

### TestDFSIO

TestDFSIO 主要用来分析 HDFS 集群的 I/O 性能。

后台执行 MapReduce 框架，其中 Map 任务以并行的方式读写文件，Reduce 任务用来收集和汇总性能数据。

启动的 Map 数量取决于文件的数量，对于每个文件都会启动一个对应的 Map。

#### 使用

主要参数如下：
```shell
TestDFSIO [genericOptions] -read [-random | -backward | -skip [-skipSize Size]] | -write | -append | -clean [-compression codecClassName] [-nrFiles N] [-size Size[B|KB|MB|GB|TB]] [-resFile resultFileName] [-bufferSize Bytes]
```

其中，`-nrFiles` 指定了总的文件数，`-size` 指定了文件的大小。

#### 例子

例如，可以使用如下例子向 HDFS 写入 100 个 1 G 的文件：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar TestDFSIO -write -nrFiles 100 -size 1GB
```

运行结果保存在当前目录下的 TestDFSIO_results.log 中，内容形式如下：
```shell
17/08/16 11:57:53 INFO fs.TestDFSIO: ----- TestDFSIO ----- : write
17/08/16 11:57:53 INFO fs.TestDFSIO:            Date & time: Wed Aug 16 11:57:53 CST 2017
17/08/16 11:57:53 INFO fs.TestDFSIO:        Number of files: 100
17/08/16 11:57:53 INFO fs.TestDFSIO: Total MBytes processed: 9.765625
17/08/16 11:57:53 INFO fs.TestDFSIO:      Throughput mb/sec: 0.11543701313285341
17/08/16 11:57:53 INFO fs.TestDFSIO: Average IO rate mb/sec: 0.12089505791664124
17/08/16 11:57:53 INFO fs.TestDFSIO:  IO rate std deviation: 0.04330682900088242
17/08/16 11:57:53 INFO fs.TestDFSIO:     Test exec time sec: 485.924
17/08/16 11:57:53 INFO fs.TestDFSIO:
```

#### 注意

1. 如果要测试读的性能，则需要在测试之前先使用 -write 参数生成相应的文件。否则，任务会报错找不到文件。
2. 在测试完成之后，建议使用 -clean 清除测试数据。
3. 结果中的数值是平均值，也就是说，如果要计算集群整体的 I/O 性能，需要将结果乘以集群中可并行运行的 container 的数量。


可以使用提供的 SliveTest 来对 HDFS 集群进行压力测试。

### SliveTest

SliveTest 的主要功能是通过大量 map 制造多种 RPC 请求，检测 NameNode 的性能。可以设定 map 数量、每个 map 发起的 RPC 请求次数、每一种 RPC 操作占总操作的百分比以及读写数量、块大小等配置。

SliveTest 主要支持 7 种 RPC 请求种类：ls、append、create、delete、mkdir、rename、read。

默认情况下，每个 map 有 1000 次 RPC请求，7 中 RPC 请求随机均匀的出现。

#### 使用

SliveTest 的主要参数如下：
```shell
usage: SliveTest 0.0.2
 -append <arg>        指定 append 操作占总操作数的百分比
 -appendSize <arg>    追加写大小，值形式 <min,max>。默认等于 blockSize
 -baseDir <arg>       运行后默认存放的文件根目录，默认为 /test/slive
 -blockSize <arg>     文件数据块大小，值形式 <min,max>。默认为 64MB
 -cleanup <arg>       执行完所有操作并报告之后，清理目录
 -create <arg>        指定 create 操作占总操作数的百分比
 -delete <arg>        指定 delete 操作占总操作数的百分比
 -dirSize <arg>       每个文件夹最多允许生成多少个文件，默认为 32
 -duration <arg>      每个 map task 持续的时间，默认值为 MAX_INT，也就是无限制
 -exitOnError         遇到第一个错误后退出
 -files <arg>         最大生成的文件数，默认为 10
 -help                Usage information
 -ls <arg>            指定 ls 操作占总操作数的百分比
 -maps <arg>          一共运行多少个 mapper，默认为 10
 -mkdir <arg>         指定 mkdir 操作占总操作数的百分比
 -ops <arg>           每个 map 跑多少个操作，默认为 1000
 -packetSize <arg>    指定写入的包大小
 -queue <arg>         指定队列名，默认为“default”
 -read <arg>          指定 read 操作占总操作数的百分比
 -readSize <arg>      读入的大小值，值形式为 <min,max>。默认无限制
 -reduces <arg>       一共运行多少个 reducer
 -rename <arg>        指定 rename 操作占总操作数的百分比
 -replication <arg>   备份数，值形式为 <min,max>。默认为 3,3
 -resFile <arg>       结果文件名，默认为“part-0000”
 -seed <arg>          随机数种子
 -sleep <arg>         在不同的操作之间随机的插入 sleep，该参数定义 sleep 的时间范围，值形式为 <min,max>。默认为 0
 -writeSize <arg>     写入大小，值形式为 <min,max>。默认等于 blockSize
```

#### 例子

例如，可使用如下命令来对集群进行压力测试：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar SliveTest -replication 1,3 -create 50 -read 50  -ls 0 -append 0 -delete 0 -mkdir 0 -rename 0 -blockSize 134217728,1342177280 -files 10000 -maps 1000 -ops 2000
```

结果保存在当前目录的 part-0000 文件中，内容形式为：
```shell
Basic report for operation type CreateOp
-------------
Measurement "bytes_written" = 10485760
Measurement "failures" = 4990
Measurement "milliseconds_taken" = 3465
Measurement "op_count" = 5000
Measurement "successes" = 10
Rate for measurement "bytes_written" = 2.886 MB/sec
Rate for measurement "op_count" = 1443.001 operations/sec
Rate for measurement "successes" = 2.886 successes/sec
-------------
Basic report for operation type ReadOp
-------------
Measurement "bytes_read" = 5232394240
Measurement "chunks_unverified" = 0
Measurement "chunks_verified" = 654039300
Measurement "files_not_found" = 10
Measurement "milliseconds_taken" = 150510
Measurement "op_count" = 5000
Measurement "successes" = 4990
Rate for measurement "bytes_read" = 33.154 MB/sec
Rate for measurement "op_count" = 33.22 operations/sec
Rate for measurement "successes" = 33.154 successes/sec
-------------
Basic report for operation type SliveMapper
-------------
Measurement "milliseconds_taken" = 516056
Measurement "op_count" = 10000
Rate for measurement "op_count" = 19.378 operations/sec
-------------
```

#### 注意

测试完成后，需要手动清除 HDFS 上的测试文件。

## YARN

## HBase