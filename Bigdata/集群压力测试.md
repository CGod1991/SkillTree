# 集群压力测试

标签：压测

---

简单介绍一些大数据集群做压力测试所使用的工具，以及测试的具体过程。

## HDFS

Hadoop 自带了一个 jar 包用来做各种的压力测试和性能测试，jar 包所在路径为 `$HADOOP_HOME/share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar`。

可以使用 TestDFSIO 对集群进行性能测试。

### TestDFSIO

TestDFSIO 主要用来分析 HDFS 集群的 I/O 性能。

后台执行 MapReduce 框架，其中 Map 任务以并行的方式读写文件，Reduce 任务用来收集和汇总性能数据。

启动的 Map 数量取决于文件的数量，对于每个文件都会启动一个对应的 Map。

#### 使用

主要参数如下：
```shell
TestDFSIO [genericOptions] -read [-random | -backward | -skip [-skipSize Size]] | -write | -append | -clean [-compression codecClassName] [-nrFiles N] [-size Size[B|KB|MB|GB|TB]] [-resFile resultFileName] [-bufferSize Bytes]
```

其中，`-nrFiles` 指定了总的文件数，`-size` 指定了文件的大小，`-resFile` 指定了运行结果保存的文件名，默认为 TestDFSIO_results.log。

#### 例子

例如，可以使用如下例子向 HDFS 写入 100 个 1 G 的文件：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar TestDFSIO -write -nrFiles 100 -size 1GB
```

运行结果保存在当前目录下的 TestDFSIO_results.log 中，内容形式如下：
```shell
17/08/16 11:57:53 INFO fs.TestDFSIO: ----- TestDFSIO ----- : write
17/08/16 11:57:53 INFO fs.TestDFSIO:            Date & time: Wed Aug 16 11:57:53 CST 2017
17/08/16 11:57:53 INFO fs.TestDFSIO:        Number of files: 100
17/08/16 11:57:53 INFO fs.TestDFSIO: Total MBytes processed: 9.765625
17/08/16 11:57:53 INFO fs.TestDFSIO:      Throughput mb/sec: 0.11543701313285341
17/08/16 11:57:53 INFO fs.TestDFSIO: Average IO rate mb/sec: 0.12089505791664124
17/08/16 11:57:53 INFO fs.TestDFSIO:  IO rate std deviation: 0.04330682900088242
17/08/16 11:57:53 INFO fs.TestDFSIO:     Test exec time sec: 485.924
17/08/16 11:57:53 INFO fs.TestDFSIO:
```

#### 注意

1. 如果要测试读的性能，则需要在测试之前先使用 -write 参数生成相应的文件。否则，任务会报错找不到文件。
2. 在测试完成之后，建议使用 -clean 清除测试数据。
3. 结果中的数值是平均值，也就是说，如果要计算集群整体的 I/O 性能，需要将结果乘以集群中可并行运行的 container 的数量。


可以使用提供的 SliveTest 来对 HDFS 集群进行压力测试。

### SliveTest

SliveTest 的主要功能是通过大量 map 制造多种 RPC 请求，检测 NameNode 的性能。可以设定 map 数量、每个 map 发起的 RPC 请求次数、每一种 RPC 操作占总操作的百分比以及读写数量、块大小等配置。

SliveTest 主要支持 7 种 RPC 请求种类：ls、append、create、delete、mkdir、rename、read。

默认情况下，每个 map 有 1000 次 RPC请求，7 中 RPC 请求随机均匀的出现。

#### 使用

SliveTest 的主要参数如下：
```shell
usage: SliveTest 0.0.2
 -append <arg>        指定 append 操作占总操作数的百分比
 -appendSize <arg>    追加写大小，值形式 <min,max>。默认等于 blockSize
 -baseDir <arg>       运行后默认存放的文件根目录，默认为 /test/slive
 -blockSize <arg>     文件数据块大小，值形式 <min,max>。默认为 64MB
 -cleanup <arg>       执行完所有操作并报告之后，清理目录
 -create <arg>        指定 create 操作占总操作数的百分比
 -delete <arg>        指定 delete 操作占总操作数的百分比
 -dirSize <arg>       每个文件夹最多允许生成多少个文件，默认为 32
 -duration <arg>      每个 map task 持续的时间，默认值为 MAX_INT，也就是无限制
 -exitOnError         遇到第一个错误后退出
 -files <arg>         最大生成的文件数，默认为 10
 -help                Usage information
 -ls <arg>            指定 ls 操作占总操作数的百分比
 -maps <arg>          一共运行多少个 mapper，默认为 10
 -mkdir <arg>         指定 mkdir 操作占总操作数的百分比
 -ops <arg>           每个 map 跑多少个操作，默认为 1000
 -packetSize <arg>    指定写入的包大小
 -queue <arg>         指定队列名，默认为“default”
 -read <arg>          指定 read 操作占总操作数的百分比
 -readSize <arg>      读入的大小值，值形式为 <min,max>。默认无限制
 -reduces <arg>       一共运行多少个 reducer
 -rename <arg>        指定 rename 操作占总操作数的百分比
 -replication <arg>   备份数，值形式为 <min,max>。默认为 3,3
 -resFile <arg>       结果文件名，默认为“part-0000”
 -seed <arg>          随机数种子
 -sleep <arg>         在不同的操作之间随机的插入 sleep，该参数定义 sleep 的时间范围，值形式为 <min,max>。默认为 0
 -writeSize <arg>     写入大小，值形式为 <min,max>。默认等于 blockSize
```

#### 例子

例如，可使用如下命令来对集群进行压力测试：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar SliveTest -replication 1,3 -create 50 -read 50  -ls 0 -append 0 -delete 0 -mkdir 0 -rename 0 -blockSize 134217728,1342177280 -files 10000 -maps 1000 -ops 2000
```

结果保存在当前目录的 part-0000 文件中，内容形式为：
```shell
Basic report for operation type CreateOp
-------------
Measurement "bytes_written" = 10485760
Measurement "failures" = 4990
Measurement "milliseconds_taken" = 3465
Measurement "op_count" = 5000
Measurement "successes" = 10
Rate for measurement "bytes_written" = 2.886 MB/sec
Rate for measurement "op_count" = 1443.001 operations/sec
Rate for measurement "successes" = 2.886 successes/sec
-------------
Basic report for operation type ReadOp
-------------
Measurement "bytes_read" = 5232394240
Measurement "chunks_unverified" = 0
Measurement "chunks_verified" = 654039300
Measurement "files_not_found" = 10
Measurement "milliseconds_taken" = 150510
Measurement "op_count" = 5000
Measurement "successes" = 4990
Rate for measurement "bytes_read" = 33.154 MB/sec
Rate for measurement "op_count" = 33.22 operations/sec
Rate for measurement "successes" = 33.154 successes/sec
-------------
Basic report for operation type SliveMapper
-------------
Measurement "milliseconds_taken" = 516056
Measurement "op_count" = 10000
Rate for measurement "op_count" = 19.378 operations/sec
-------------
```

#### 注意

测试完成后，需要手动清除 HDFS 上的测试文件。

## YARN

对于 YARN 的压力测试，可以通过 TeraSort 基准测试来实现。

使用的 jar 包路径为 `$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar`。

### TeraSort

TeraSort 是 Hadoop 中比较常用的测试，主要用来测试 MapReduce 集群的性能。

TeraSort 利用 MapReduce 来尽可能的对指定的数据量进行排序，以此来测试 MapReduce 集群的性能。TeraSort 可以很好的对 MapReduce 框架的每个过程进行压力测试，为调优和配置 Hadoop 集群提供了一个合理的参考。

整个 TeraSort 测试的过程主要分为三步：
1. 使用 TeraGen 生成测试数据；
2. 利用 TeraSort 对测试数据进行排序；
3. 用 TeraValidate 验证排序的结果数据。

下面对每个步骤依次进行介绍。

#### teragen

teragen 的用法如下：
```shell
teragen <num rows> <output dir>
```
其中，`num row` 指定了随机生成的数据行数，需要注意的是，这里每一行的大小为 100 B。`output dir` 指定了生成的数据在 HDFS 上的存储路径。

例如，可通过如下命令生成 100 GB 数据，存储在 HDFS 上的 /benchmarks/terasort-input：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar teragen 1000000000 /benchmarks/terasort-input
```

#### terasort

使用 teragen 生成了测试数据之后，就可以使用 terasort 对这些数据进行排序。

terasort 的用法如下：
```shell
terasort <input dir> <output dir>
```

例如，可通过如下命令对生成的 100 GB 数据进行排序：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar terasort /benchmarks/terasort-input /benchmarks/terasort-output
```

#### teravalidate

在 terasort 运行完成后，可使用 teravalidate 来验证 terasort 的输出数据是否有序。如果检测到有问题，teravalidate 会将乱序的 key 输出到输出目录。

teravalidate 的用法如下：
```shell
teravalidate <out-dir> <report-dir>
```

其中，`out-dir` 是 terasort 的输出目录。

例如，可使用如下命令对 terasort 的输出结果进行验证：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar teravalidate /benchmarks/terasort-output /benchmarks/terasort-validate
```
查看 /benchmarks/terasort-validate 目录下，输出文件显示 checksum 则表示排序没有问题：
```shell
[root@hadoop1 hadoop]# bin/hdfs dfs -cat /benchmarks/terasort-validate/part-r-00000
checksum	1f9ffe645ec
```

## HBase

HBase 集群的压力测试工具，常用的是 YCSB。

### YCSB

YCSB（Yahoo! Cloud Serving Benchmark）是雅虎开源的一款通用的性能测试工具，可以对各类 NoSQL 产品进行性能测试。

与 HBase 自带的性能测试工具 PE 相比，YCSB 更灵活，可以定制测试的场景（如读多写少或读少写多）。而且在测试完成后，还会汇总整体的测试情况。

#### 安装

由于我们使用的 HBase 的版本是 1.2，而 YCSB 最新版的安装包里只支持 HBase 1.0 版本，所以需要我们下载最先的 YCSB 源码，进行编译。

YCSB 源码从 [这里](https://github.com/brianfrankcooper/YCSB) 下载。

编译完成之后，在 YCSB/distribution/target 目录下会生成安装包，解压到指定目录即完成安装。

使用 YCSB 对 HBase 进行测试主要分为三部分：创建测试表、加载数据和执行测试。

#### 创建测试表

在使用 YCSB 之前，需要在 HBase 中手动创建测试用的表。

在 HBase Shell 中分别执行以下命令，创建表：
```shell
hbase(main):001:0> n_splits = 200 # HBase recommends (10 * number of regionservers)
hbase(main):002:0> create 'usertable', 'family', {SPLITS => (1..n_splits).map {|i| "user#{1000+i*(9999-1000)/n_splits}"}}

```

#### 加载数据

执行如下命令，生成测试用数据：
```shell
cd $YCSB_HOME

bin/ycsb load hbase12 -P workloads/workloada -cp $HBASE_HOME/conf -p table=usertable -p columnfamily=family
```

其中：
- `hbase12`：表示使用的数据库为 HBase1.2 版本。
- `-P`：指定加载的配置文件。
- `workloada`：YCSB 自带了不同场景的配置文件，可以根据需要进行定制。存放在 `workloads` 目录下，比如 `workloada`（读写均衡）、`workloadb`（读多写少）、`workloadc`（只读）等。
- `-cp`：指定使用的 HBase 的配置文件，并加入到 classpath 中。
- `-p`：指定参数配置，在这里指定了数据加载到的表和列簇。

#### 执行测试

数据加载完成后，就可以进行测试。使用以下命令执行测试，并将结果写入 log 文件：
```shell
bin/ycsb run hbase12 -P workloads/workloada -threads 10 -cp $HBASE_HOME/conf -p table=usertable -p columnfamily=family -p measurementtype=timeseries -p timeseries.granularity=2000 > log
```
其中：
- `threads`：配置了并发线程数。
- `-p measurementtype=timeseries -p timeseries.granularity=2000`：指明了 YCSB 客户端多长时间汇总一次延迟，`timeseries.granularity` 的单位为毫秒，所以这里指定了每 2 秒记录一次本 2 秒的平均延迟。

#### 结果

测试的结果内容形式如下：
```shell
[OVERALL], RunTime(ms), 4000
[OVERALL], Throughput(ops/sec), 250.0
[TOTAL_GCS_Copy], Count, 5
[TOTAL_GC_TIME_Copy], Time(ms), 39
[TOTAL_GC_TIME_%_Copy], Time(%), 0.975
[TOTAL_GCS_MarkSweepCompact], Count, 0
[TOTAL_GC_TIME_MarkSweepCompact], Time(ms), 0
[TOTAL_GC_TIME_%_MarkSweepCompact], Time(%), 0.0
[TOTAL_GCs], Count, 5
[TOTAL_GC_TIME], Time(ms), 39
[TOTAL_GC_TIME_%], Time(%), 0.975
[READ], Operations, 502
[READ], AverageLatency(us), 7217.687250996016
[READ], MinLatency(us), 362
[READ], MaxLatency(us), 262745
[READ], Return=OK, 502
[READ], 0, 7217.687250996016
[CLEANUP], Operations, 20
[CLEANUP], AverageLatency(us), 3897.15
[CLEANUP], MinLatency(us), 5
[CLEANUP], MaxLatency(us), 75648
[CLEANUP], 0, 3897.15
[UPDATE], Operations, 498
```


