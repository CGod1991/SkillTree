# 集群压力测试

标签：压测

---

简单介绍一些大数据集群做压力测试所使用的工具，以及测试的具体过程。

## HDFS

Hadoop 自带了一个 jar 包用来做各种的压力测试和性能测试，jar 包所在路径为 `$HADOOP_HOME/share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar`。

可以使用 TestDFSIO 对集群进行性能测试。

### TestDFSIO

TestDFSIO 主要用来分析 HDFS 集群的 I/O 性能。

后台执行 MapReduce 框架，其中 Map 任务以并行的方式读写文件，Reduce 任务用来收集和汇总性能数据。

启动的 Map 数量取决于文件的数量，对于每个文件都会启动一个对应的 Map。

#### 使用

主要参数如下：
```shell
TestDFSIO [genericOptions] -read [-random | -backward | -skip [-skipSize Size]] | -write | -append | -clean [-compression codecClassName] [-nrFiles N] [-size Size[B|KB|MB|GB|TB]] [-resFile resultFileName] [-bufferSize Bytes]
```

其中，`-nrFiles` 指定了总的文件数，`-size` 指定了文件的大小，`-resFile` 指定了运行结果保存的文件名，默认为 TestDFSIO_results.log。

#### 例子

例如，可以使用如下例子向 HDFS 写入 100 个 1 G 的文件：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar TestDFSIO -write -nrFiles 100 -size 1GB
```

运行结果保存在当前目录下的 TestDFSIO_results.log 中，内容形式如下：
```shell
17/08/16 11:57:53 INFO fs.TestDFSIO: ----- TestDFSIO ----- : write
17/08/16 11:57:53 INFO fs.TestDFSIO:            Date & time: Wed Aug 16 11:57:53 CST 2017
17/08/16 11:57:53 INFO fs.TestDFSIO:        Number of files: 100
17/08/16 11:57:53 INFO fs.TestDFSIO: Total MBytes processed: 9.765625
17/08/16 11:57:53 INFO fs.TestDFSIO:      Throughput mb/sec: 0.11543701313285341
17/08/16 11:57:53 INFO fs.TestDFSIO: Average IO rate mb/sec: 0.12089505791664124
17/08/16 11:57:53 INFO fs.TestDFSIO:  IO rate std deviation: 0.04330682900088242
17/08/16 11:57:53 INFO fs.TestDFSIO:     Test exec time sec: 485.924
17/08/16 11:57:53 INFO fs.TestDFSIO:
```

#### 注意

1. 如果要测试读的性能，则需要在测试之前先使用 -write 参数生成相应的文件。否则，任务会报错找不到文件。
2. 在测试完成之后，建议使用 -clean 清除测试数据。
3. 结果中的数值是平均值，也就是说，如果要计算集群整体的 I/O 性能，需要将结果乘以集群中可并行运行的 container 的数量。


可以使用提供的 SliveTest 来对 HDFS 集群进行压力测试。

### SliveTest

SliveTest 的主要功能是通过大量 map 制造多种 RPC 请求，检测 NameNode 的性能。可以设定 map 数量、每个 map 发起的 RPC 请求次数、每一种 RPC 操作占总操作的百分比以及读写数量、块大小等配置。

SliveTest 主要支持 7 种 RPC 请求种类：ls、append、create、delete、mkdir、rename、read。

默认情况下，每个 map 有 1000 次 RPC请求，7 中 RPC 请求随机均匀的出现。

#### 使用

SliveTest 的主要参数如下：
```shell
usage: SliveTest 0.0.2
 -append <arg>        指定 append 操作占总操作数的百分比
 -appendSize <arg>    追加写大小，值形式 <min,max>。默认等于 blockSize
 -baseDir <arg>       运行后默认存放的文件根目录，默认为 /test/slive
 -blockSize <arg>     文件数据块大小，值形式 <min,max>。默认为 64MB
 -cleanup <arg>       执行完所有操作并报告之后，清理目录
 -create <arg>        指定 create 操作占总操作数的百分比
 -delete <arg>        指定 delete 操作占总操作数的百分比
 -dirSize <arg>       每个文件夹最多允许生成多少个文件，默认为 32
 -duration <arg>      每个 map task 持续的时间，默认值为 MAX_INT，也就是无限制
 -exitOnError         遇到第一个错误后退出
 -files <arg>         最大生成的文件数，默认为 10
 -help                Usage information
 -ls <arg>            指定 ls 操作占总操作数的百分比
 -maps <arg>          一共运行多少个 mapper，默认为 10
 -mkdir <arg>         指定 mkdir 操作占总操作数的百分比
 -ops <arg>           每个 map 跑多少个操作，默认为 1000
 -packetSize <arg>    指定写入的包大小
 -queue <arg>         指定队列名，默认为“default”
 -read <arg>          指定 read 操作占总操作数的百分比
 -readSize <arg>      读入的大小值，值形式为 <min,max>。默认无限制
 -reduces <arg>       一共运行多少个 reducer
 -rename <arg>        指定 rename 操作占总操作数的百分比
 -replication <arg>   备份数，值形式为 <min,max>。默认为 3,3
 -resFile <arg>       结果文件名，默认为“part-0000”
 -seed <arg>          随机数种子
 -sleep <arg>         在不同的操作之间随机的插入 sleep，该参数定义 sleep 的时间范围，值形式为 <min,max>。默认为 0
 -writeSize <arg>     写入大小，值形式为 <min,max>。默认等于 blockSize
```

#### 例子

例如，可使用如下命令来对集群进行压力测试：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce2/hadoop-mapreduce-client-jobclient-2.6.0-cdh5.8.2-tests.jar SliveTest -replication 1,3 -create 50 -read 50  -ls 0 -append 0 -delete 0 -mkdir 0 -rename 0 -blockSize 134217728,1342177280 -files 10000 -maps 1000 -ops 2000
```

结果保存在当前目录的 part-0000 文件中，内容形式为：
```shell
Basic report for operation type CreateOp
-------------
Measurement "bytes_written" = 10485760
Measurement "failures" = 4990
Measurement "milliseconds_taken" = 3465
Measurement "op_count" = 5000
Measurement "successes" = 10
Rate for measurement "bytes_written" = 2.886 MB/sec
Rate for measurement "op_count" = 1443.001 operations/sec
Rate for measurement "successes" = 2.886 successes/sec
-------------
Basic report for operation type ReadOp
-------------
Measurement "bytes_read" = 5232394240
Measurement "chunks_unverified" = 0
Measurement "chunks_verified" = 654039300
Measurement "files_not_found" = 10
Measurement "milliseconds_taken" = 150510
Measurement "op_count" = 5000
Measurement "successes" = 4990
Rate for measurement "bytes_read" = 33.154 MB/sec
Rate for measurement "op_count" = 33.22 operations/sec
Rate for measurement "successes" = 33.154 successes/sec
-------------
Basic report for operation type SliveMapper
-------------
Measurement "milliseconds_taken" = 516056
Measurement "op_count" = 10000
Rate for measurement "op_count" = 19.378 operations/sec
-------------
```

#### 注意

测试完成后，需要手动清除 HDFS 上的测试文件。

## YARN

对于 YARN 的压力测试，可以通过 TeraSort 基准测试来实现。

使用的 jar 包路径为 `$HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar`。

### TeraSort

TeraSort 是 Hadoop 中比较常用的测试，主要用来测试 MapReduce 集群的性能。

TeraSort 利用 MapReduce 来尽可能的对指定的数据量进行排序，以此来测试 MapReduce 集群的性能。TeraSort 可以很好的对 MapReduce 框架的每个过程进行压力测试，为调优和配置 Hadoop 集群提供了一个合理的参考。

整个 TeraSort 测试的过程主要分为三步：
1. 使用 TeraGen 生成测试数据；
2. 利用 TeraSort 对测试数据进行排序；
3. 用 TeraValidate 验证排序的结果数据。

下面对每个步骤依次进行介绍。

#### teragen

teragen 的用法如下：
```shell
teragen <num rows> <output dir>
```
其中，`num row` 指定了随机生成的数据行数，需要注意的是，这里每一行的大小为 100 B。`output dir` 指定了生成的数据在 HDFS 上的存储路径。

例如，可通过如下命令生成 100 GB 数据，存储在 HDFS 上的 /benchmarks/terasort-input：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar teragen 1000000000 /benchmarks/terasort-input
```

#### terasort

使用 teragen 生成了测试数据之后，就可以使用 terasort 对这些数据进行排序。

terasort 的用法如下：
```shell
terasort <input dir> <output dir>
```

例如，可通过如下命令对生成的 100 GB 数据进行排序：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar terasort /benchmarks/terasort-input /benchmarks/terasort-output
```

#### teravalidate

在 terasort 运行完成后，可使用 teravalidate 来验证 terasort 的输出数据是否有序。如果检测到有问题，teravalidate 会将乱序的 key 输出到输出目录。

teravalidate 的用法如下：
```shell
teravalidate <out-dir> <report-dir>
```

其中，`out-dir` 是 terasort 的输出目录。

例如，可使用如下命令对 terasort 的输出结果进行验证：
```shell
$HADOOP_HOME/bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0-cdh5.8.2.jar teravalidate /benchmarks/terasort-output /benchmarks/terasort-validate
```
查看 /benchmarks/terasort-validate 目录下，输出文件显示 checksum 则表示排序没有问题：
```shell
[root@hadoop1 hadoop]# bin/hdfs dfs -cat /benchmarks/terasort-validate/part-r-00000
checksum	1f9ffe645ec
```

## HBase

HBase 集群的压力测试工具，常用的是 YCSB。

### YCSB

YCSB（Yahoo! Cloud Serving Benchmark）是雅虎开源的一款通用的性能测试工具，可以对各类 NoSQL 产品进行性能测试。

与 HBase 自带的性能测试工具 PE 相比，YCSB 更灵活，可以定制测试的场景（如读多写少或读少写多）。而且在测试完成后，还会汇总整体的测试情况。

#### 安装

由于我们使用的 HBase 的版本是 1.2，而 YCSB 最新版的安装包里只支持 HBase 1.0 版本，所以需要我们下载最先的 YCSB 源码，进行编译。

YCSB 源码从 [这里](https://github.com/brianfrankcooper/YCSB) 下载。

编译完成之后，在 YCSB/distribution/target 目录下会生成安装包，解压到指定目录即完成安装。

使用 YCSB 对 HBase 进行测试主要分为三部分：创建测试表、加载数据和执行测试。

#### 创建测试表

在使用 YCSB 之前，需要在 HBase 中手动创建测试用的表。

在 HBase Shell 中分别执行以下命令，创建表：
```shell
hbase(main):001:0> n_splits = 200 # HBase recommends (10 * number of regionservers)
hbase(main):002:0> create 'usertable', 'family', {SPLITS => (1..n_splits).map {|i| "user#{1000+i*(9999-1000)/n_splits}"}}

```

#### 加载数据

执行如下命令，生成测试用数据：
```shell
cd $YCSB_HOME

bin/ycsb load hbase12 -P workloads/workloada -cp $HBASE_HOME/conf -p table=usertable -p columnfamily=family
```

其中：
- `hbase12`：表示使用的数据库为 HBase1.2 版本。
- `-P`：指定加载的配置文件。
- `workloada`：YCSB 自带了不同场景的配置文件，可以根据需要进行定制。存放在 `workloads` 目录下，比如 `workloada`（读写均衡）、`workloadb`（读多写少）、`workloadc`（只读）、`workloadd`（读最近的记录）、`workloade`（读小范围记录）、`workloadf`（读-修改-写）。
- `-cp`：指定使用的 HBase 的配置文件，并加入到 classpath 中。
- `-p`：指定参数配置，在这里指定了数据加载到的表和列簇。

#### 执行测试

数据加载完成后，就可以进行测试。使用以下命令执行测试，并将结果写入 log 文件：
```shell
bin/ycsb run hbase12 -P workloads/workloada -threads 10 -cp $HBASE_HOME/conf -p table=usertable -p columnfamily=family -p measurementtype=timeseries -p timeseries.granularity=2000 > log
```
其中：
- `threads`：配置了并发线程数。
- `measurementtype`：表示支持的测量结果类型，有直方图（`histogram.buckets`）和时间序列（`timeseries.granularity`）。默认：直方图。
- `-p measurementtype=timeseries -p timeseries.granularity=2000`：指明了 YCSB 客户端多长时间汇总一次延迟，`timeseries.granularity` 的单位为毫秒，所以这里指定了每 2 秒记录一次本 2 秒的平均延迟。

#### 结果

测试的结果内容形式如下：
```shell
[OVERALL], RunTime(ms), 4000
[OVERALL], Throughput(ops/sec), 250.0
[TOTAL_GCS_Copy], Count, 5
[TOTAL_GC_TIME_Copy], Time(ms), 39
[TOTAL_GC_TIME_%_Copy], Time(%), 0.975
[TOTAL_GCS_MarkSweepCompact], Count, 0
[TOTAL_GC_TIME_MarkSweepCompact], Time(ms), 0
[TOTAL_GC_TIME_%_MarkSweepCompact], Time(%), 0.0
[TOTAL_GCs], Count, 5
[TOTAL_GC_TIME], Time(ms), 39
[TOTAL_GC_TIME_%], Time(%), 0.975
[READ], Operations, 502
[READ], AverageLatency(us), 7217.687250996016
[READ], MinLatency(us), 362
[READ], MaxLatency(us), 262745
[READ], Return=OK, 502
[READ], 0, 7217.687250996016
[CLEANUP], Operations, 20
[CLEANUP], AverageLatency(us), 3897.15
[CLEANUP], MinLatency(us), 5
[CLEANUP], MaxLatency(us), 75648
[CLEANUP], 0, 3897.15
[UPDATE], Operations, 498
```

#### workload 文件属性

在 workload 属性文件中可以指定以下属性的值：
```shell
fieldcount：一条记录中的字段数（默认：10）
fieldlength：每个字段的大小（默认：100）
readallfields：是否应该读取所有字段（true）或者只有一个字段（false）（默认：true）
readproportion：读操作的比例（默认：0.95）
updateproportion：更新操作的比例（默认：0.05）
insertproportion：插入操作的比例（默认：0）
scanproportion：遍历操作的比例（默认：0）
readmodifywriteproportion：读-修改-写一条记录的操作的比例（默认：0）
requestdistribution：选择要操作的记录的分布——均匀分布（uniform）、Zipfian分布（zipfian）或者最近分布（latest）（默认：uniform）
maxscanlength：对于遍历操作，最大的遍历记录数（默认：1000）
scanlengthdistribution：对于遍历操作，要遍历的记录数的分布，在1到maxscanlength之间（默认：uniform）
insertorder：记录是否应该有序插入（ordered），或者是哈希顺序（hashed）（默认：hashed）
operationcount：要进行的操作数数量
maxexecutiontime：最大的执行时间（单位为秒）。当操作数达到规定值或者执行时间达到规定最大值时基准测试会停止。
table：表的名称（默认：usertable）
recordcount：装载进数据库的初始记录数（默认：0）
```



